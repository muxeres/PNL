{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muxeres/PNL/blob/master/C%C3%B3pia_de_%5BONLINE%5D_Similaridade_L%C3%A9xica.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pDgXV8lvSd8"
      },
      "source": [
        "# Similaridade Léxica\n",
        "## Processamento de Linguagem Natural\n",
        "Nesta atividade você realizará atividades práticas relacionadas a  **Similaridade léxica**, visando entender qual o seu papel nas mais diversas aplicações de PLN.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDCy7V1GxQKH"
      },
      "source": [
        "##**Medidas de similaridade**\n",
        "Existe uma série de diferentes cálculos/medidas que indicam a similaridade léxica entre palavras, as chamamos de *string-based*.\n",
        "\n",
        "![String-based similarity measures](https://docs.google.com/uc?export=download&id=1iO4zT9lTIO4-XsAB-P9_BddOIJwjwMRJ)\n",
        "\n",
        "A seguir uma série de exemplos de algumas das medidas de similaridade léxica da figura acima."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyxAUVnG5yoG"
      },
      "source": [
        "### **Levenshtein (edit) distance**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMRu3cNl_7xO"
      },
      "source": [
        "A distância de Levenshtein entre duas palavras é o número mínimo de edições de um caractere (inserções, exclusões ou substituições) necessárias para alterar uma palavra pela outra. Usaremos para comparar **PALAVRAS/TOKENS**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k69kSOHL_79J"
      },
      "source": [
        "# Define 4 palavras diferentes\n",
        "p1 = \"padeiro\"\n",
        "p2 = \"pandeiro\"\n",
        "p3 = \"bombeiro\"\n",
        "p4 = \"padaria\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgPDaB-XCBYl"
      },
      "source": [
        "# Não há necessidade de implementar a função de edit distance visto que o NLTK já a implementa\n",
        "import nltk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXprcqetG_PL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57f8f9d7-a2d1-43cd-abbf-f38260173556"
      },
      "source": [
        "nltk.edit_distance(p1, p2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwBEV_RuHHx4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "052e576c-b8b1-4124-df8d-8e7cb44dac30"
      },
      "source": [
        "nltk.edit_distance(p1, p3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swHvj9JFHH5n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebed25ad-7460-400e-cb91-8a086a2bd828"
      },
      "source": [
        "nltk.edit_distance(p1, p4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuaJGq5WI7si",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c02ec135-c51a-4b3a-ba1f-487b73bc29b4"
      },
      "source": [
        "nltk.edit_distance(p3, p4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VFowjBnHivA"
      },
      "source": [
        "#### Atividade prática - Construindo um **verificador ortográfico simples**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7J_G_c9KaAR"
      },
      "source": [
        "# Lista contendo o dicionário de palavras válidas\n",
        "dicionario = ['beneficente','cumprimento', 'comprimento', 'tráfego', 'tráfico', 'iminente', 'eminente', 'descrição', 'discrição']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28Z5JxbEMJ4K"
      },
      "source": [
        "# Função que verifica se palavra está no dicionário\n",
        "def verificar(p):\n",
        "  # Se palavra não está no dicionário\n",
        "  if p not in dicionario:\n",
        "\n",
        "    print(\"Palavra incorreta!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nkFhMHEKPyK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d21d851c-5b04-4759-f556-74f02ccfa041"
      },
      "source": [
        "#A seguir pediremos que o usuário digite uma palavra\n",
        "palavra = input(\"Digite uma palavra: \")\n",
        "\n",
        "# Verifica palavra informada pelo usuário\n",
        "verificar(palavra)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Digite uma palavra: palavrão\n",
            "Palavra incorreta!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFQobiPjN_M5"
      },
      "source": [
        "\n",
        "Re-implemente a função `verificar(p)` de modo que:\n",
        "1.  Caso a palavra digitada não exista no dicionário, ela sugira todas as outras que tenham uma distância de edição de valor 1 da palavra digitada.\n",
        "> **DICA**: Para percorrer a lista de palavras você pode utilizar o comando `for palavra in dicionario:`\n",
        "2.  Ao invés de receber apenas uma palavra, a função receba uma sentença inteira, faça a tokenização da mesma, e ofereça sugestões para todas palavras que nao se encontram no dicionário (caso as mesmas tenham distância de edição igual a 1)\n",
        "3. **BÔNUS**: Obter uma lista de palavras de maior abrangência, abrir arquivo e popular o dicionário (https://github.com/pythonprobr/palavras)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_gEpCKzES5m"
      },
      "source": [
        "### **N-grams**\n",
        "O N-grams são basicamente um conjunto de caracteres/palavras co-ocorrentes em uma determinada janela de abertura. Usaremos tanto para comparar **CARACTERES** quanto **PALAVRAS**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9Eq74Kb1aWa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d1bbe76-eb75-4da1-e5b6-a591b176d585"
      },
      "source": [
        "# Não há necessidade de implementar uma função de n-grams - o NLTK já implementa\n",
        "import nltk\n",
        "from nltk.util import ngrams\n",
        "# Necessário pois utilizaremos o tokenizador\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1s3lAwk2dIk"
      },
      "source": [
        "#### N-Grams de **PALAVRAS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoFv6P1y0AHf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cb91a74-a285-4585-af5f-abfcecd48870"
      },
      "source": [
        "# Função para gerar n-grams de palavras a partir de uma sentença.\n",
        "def extrair_ngrams_palavras(sent, n):\n",
        "    n_grams = ngrams(nltk.word_tokenize(sent, language='portuguese'), n)\n",
        "    return [ ' '.join(grams) for grams in n_grams]\n",
        "\n",
        "texto = 'Esta é uma sentença para testarmos n-grams de palavras.'\n",
        "\n",
        "print(\"1-gram: \", extrair_ngrams_palavras(texto, 1))\n",
        "print(\"2-gram: \", extrair_ngrams_palavras(texto, 2))\n",
        "print(\"3-gram: \", extrair_ngrams_palavras(texto, 3))\n",
        "print(\"4-gram: \", extrair_ngrams_palavras(texto, 4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1-gram:  ['Esta', 'é', 'uma', 'sentença', 'para', 'testarmos', 'n-grams', 'de', 'palavras', '.']\n",
            "2-gram:  ['Esta é', 'é uma', 'uma sentença', 'sentença para', 'para testarmos', 'testarmos n-grams', 'n-grams de', 'de palavras', 'palavras .']\n",
            "3-gram:  ['Esta é uma', 'é uma sentença', 'uma sentença para', 'sentença para testarmos', 'para testarmos n-grams', 'testarmos n-grams de', 'n-grams de palavras', 'de palavras .']\n",
            "4-gram:  ['Esta é uma sentença', 'é uma sentença para', 'uma sentença para testarmos', 'sentença para testarmos n-grams', 'para testarmos n-grams de', 'testarmos n-grams de palavras', 'n-grams de palavras .']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rpqjUaB2luu"
      },
      "source": [
        "#### N-Grams de **CARACTERES**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFqLcCBK2l4M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "012d2b37-80f1-424d-8201-b52f8c896fa5"
      },
      "source": [
        "# Função para gerar n-grams de caracteres a partir de um texto.\n",
        "def extrair_ngrams_char(texto, n):\n",
        "  # Cria lista com caracteres\n",
        "  chars = [c for c in texto]\n",
        "  n_grams = ngrams(chars,n)\n",
        "  return [ ' '.join(grams) for grams in n_grams]\n",
        "\n",
        "texto = \"Sentença para testarmos n-grams de caracteres\"\n",
        "\n",
        "print(\"1-gram: \", extrair_ngrams_char(texto,1))\n",
        "print(\"2-gram: \", extrair_ngrams_char(texto,2))\n",
        "print(\"3-gram: \", extrair_ngrams_char(texto,3))\n",
        "print(\"4-gram: \", extrair_ngrams_char(texto,4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1-gram:  ['S', 'e', 'n', 't', 'e', 'n', 'ç', 'a', ' ', 'p', 'a', 'r', 'a', ' ', 't', 'e', 's', 't', 'a', 'r', 'm', 'o', 's', ' ', 'n', '-', 'g', 'r', 'a', 'm', 's', ' ', 'd', 'e', ' ', 'c', 'a', 'r', 'a', 'c', 't', 'e', 'r', 'e', 's']\n",
            "2-gram:  ['S e', 'e n', 'n t', 't e', 'e n', 'n ç', 'ç a', 'a  ', '  p', 'p a', 'a r', 'r a', 'a  ', '  t', 't e', 'e s', 's t', 't a', 'a r', 'r m', 'm o', 'o s', 's  ', '  n', 'n -', '- g', 'g r', 'r a', 'a m', 'm s', 's  ', '  d', 'd e', 'e  ', '  c', 'c a', 'a r', 'r a', 'a c', 'c t', 't e', 'e r', 'r e', 'e s']\n",
            "3-gram:  ['S e n', 'e n t', 'n t e', 't e n', 'e n ç', 'n ç a', 'ç a  ', 'a   p', '  p a', 'p a r', 'a r a', 'r a  ', 'a   t', '  t e', 't e s', 'e s t', 's t a', 't a r', 'a r m', 'r m o', 'm o s', 'o s  ', 's   n', '  n -', 'n - g', '- g r', 'g r a', 'r a m', 'a m s', 'm s  ', 's   d', '  d e', 'd e  ', 'e   c', '  c a', 'c a r', 'a r a', 'r a c', 'a c t', 'c t e', 't e r', 'e r e', 'r e s']\n",
            "4-gram:  ['S e n t', 'e n t e', 'n t e n', 't e n ç', 'e n ç a', 'n ç a  ', 'ç a   p', 'a   p a', '  p a r', 'p a r a', 'a r a  ', 'r a   t', 'a   t e', '  t e s', 't e s t', 'e s t a', 's t a r', 't a r m', 'a r m o', 'r m o s', 'm o s  ', 'o s   n', 's   n -', '  n - g', 'n - g r', '- g r a', 'g r a m', 'r a m s', 'a m s  ', 'm s   d', 's   d e', '  d e  ', 'd e   c', 'e   c a', '  c a r', 'c a r a', 'a r a c', 'r a c t', 'a c t e', 'c t e r', 't e r e', 'e r e s']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6p_NS7JG6xc3"
      },
      "source": [
        "> #### **IMPORTANTE**: Mas quais seriam algumas das aplicações dos n-grams?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kfsGdk-6DNW1"
      },
      "source": [
        "#### 1) Reconhecimento de entidades / Chunking\n",
        "Imagine que você tenha um corpus (conjunto de documentos) e visualize os seguintes n-grams:\n",
        "\n",
        "1.   São Paulo (2-gram)\n",
        "2.   processamento de linguagem natural (4-gram)\n",
        "3.   o presidente alega que é inocente (6-gram)\n",
        "\n",
        "Ao fazermos um levantamento de frequência, possivelmente os exemplos 1 e 2 ocorram com mais frequência no corpus. Agora se aplicarmos um modelo de probabilidade podemos **encontrar entidades** compostas por múltiplas palavras no texto.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwNbBzdpDgvF"
      },
      "source": [
        "#### 2) Predição de palavras\n",
        "Seguindo a mesma linha anterior, é possível também utilizar os n-grams para fazer **predições de palavras**. Por exemplo, se houver a sentença parcial \"*Meu beatle favorito é*\", a probabilidade da próxima palavra ser \"*John*\", \"*Paul*\", \"*George*\" ou \"*Ringo*\" é bem maior que o restante das palavras do vocabulário."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DybjX5nsDq4i"
      },
      "source": [
        "#### 3) Correção ortográfica\n",
        "A sentença \"*beba vino*\" poderia ser corrigida para \"*beba vinho*\" se você soubesse que a palavra \"*vinho*\" tem uma alta probabilidade de ocorrência após a palavra \"*beba*\". Além disso, a sobreposição de letras entre \"*vino*\" e \"*vinho*\" é alta (i.e., baixa distância de edição)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUIhr-8wDIS0"
      },
      "source": [
        "#### 4) e por fim, nosso assunto atual, *Similaridade léxica*\n",
        "Vamos extrair 2-grams de caracteres das duas palavras a seguir."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6bwpBCZMjuP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7caf9860-e88e-4650-ea50-c4cb8031055b"
      },
      "source": [
        "p1 = \"parar\"\n",
        "p2 = \"parado\"\n",
        "\n",
        "# 4 bi-grams - 2 únicos\n",
        "print(\"2-grams: \", extrair_ngrams_char(p1,2))\n",
        "# 5 bi-grams - 5 únicos\n",
        "print(\"2-grams: \", extrair_ngrams_char(p2,2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2-grams:  ['p a', 'a r', 'r a', 'a r']\n",
            "2-grams:  ['p a', 'a r', 'r a', 'a d', 'd o']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bgzq2w2PNULy"
      },
      "source": [
        "Para **cálculo de similaridade utilizando n-grams** usamos a fórmula: `S = 2C / A + B`\n",
        "\n",
        "Onde:\n",
        "* A é o número de n-grams únicos na primeira palavra\n",
        "* B é o número de n-grams únicos na segunda palavra\n",
        "* C é o número de n-grams únicos compartilhados\n",
        "\n",
        "Portanto, neste exemplo o cálculo ficaria: `S = 2 * 2 / 2 + 5 = 0.57`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qv49o9wGSsER"
      },
      "source": [
        "# Obtém os N-Grams únicos\n",
        "def uniqueNgrams(ngrams):\n",
        "\n",
        "  ngrams = [item for item in ngrams if ngrams.count(item) == 1]\n",
        "\n",
        "  return ngrams\n",
        "\n",
        "# Obtém os N-Grams compartilhados\n",
        "def sharedNgrams(ng1, ng2):\n",
        "\n",
        "  return list(set(ng1) & set(ng2))\n",
        "\n",
        "# Calcula a similaridade através dos N-Grams\n",
        "def nGramsSimilarity(ng1, ng2):\n",
        "\n",
        "  # Obtém N-Grams únicos para cada palavra\n",
        "  ung1 = uniqueNgrams(ng1)\n",
        "  ung2 = uniqueNgrams(ng2)\n",
        "\n",
        "  #Número de N-Grams únicos da palavra 1\n",
        "  A = len(ung1)\n",
        "  #Número de N-Grams únicos da palavra 2\n",
        "  B = len(ung2)\n",
        "  #Número de N-Grams compartilhados entre as palavras\n",
        "  C = len(sharedNgrams(ung1, ung2))\n",
        "\n",
        "  return (2 * C) / (A + B)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHa0n40pTaTm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c1d6fdd-78c5-476a-f7a6-bfc2c02465fa"
      },
      "source": [
        "nGramsSimilarity(extrair_ngrams_char(p1,2), extrair_ngrams_char(p2,2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5714285714285714"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDCM3z9ZEUC3"
      },
      "source": [
        "### **Jaccard distance**\n",
        "\n",
        "A distância de Jaccard é definida como o *tamanho da interseção dividida pelo tamanho da união de dois conjuntos*. Usaremos tanto para comparar **CARACTERES** quanto **PALAVRAS**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEJ_GDKHYQaq"
      },
      "source": [
        "Sentença 1: Eu gosto de fazer programas usando processamento de linguagem natural\n",
        "\n",
        "Sentença 2: Eu sei programar técnicas de processamento de linguagem natural\n",
        "\n",
        "![String-based similarity measures](https://docs.google.com/uc?export=download&id=11Wh0zM0nTqDIMPSjgM3S3LSgT9K1Xlcr)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sz8T3_reZP9j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c7c6b29-da97-4e2c-c74e-c68a7c7a237c"
      },
      "source": [
        "# Não há necessidade de implementar uma função de jaccard - o NLTK já implementa\n",
        "import nltk\n",
        "# Necessário pois utilizaremos o tokenizador\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-bkWpY8Z8wM"
      },
      "source": [
        "#### Jaccard em **CARACTERES**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKyWdTdgZ9Ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38a37b0f-f3f5-499f-b3c4-d3021cd627c3"
      },
      "source": [
        "w1 = set('tráfico')\n",
        "w2 = set('tráfego')\n",
        "\n",
        "nltk.jaccard_distance(w1, w2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4444444444444444"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTk3KySS8nU5"
      },
      "source": [
        "\n",
        "\n",
        "> **IMPORTANTE**: Esta medida calcula a **distância** entre os dois termos, portanto quanto maior o valor, mais distantes (diferentes) são os termos!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-QviROEaW1q"
      },
      "source": [
        "\n",
        "\n",
        "> **ATENÇÃO**: a função `jaccard_distance()` não aceita strings, você deve transformar sua entrada em `set`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcZgge41Z9KG"
      },
      "source": [
        "#### Jaccard em **PALAVRAS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obyaiWXCZ9UN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e3a96fc-336d-40f7-8c37-7208e7efa65d"
      },
      "source": [
        "s1 = 'Eu gosto de fazer programas usando processamento de linguagem natural'\n",
        "s2 = 'Eu sei programar técnicas de processamento de linguagem natural'\n",
        "\n",
        "# Tokeniza e transforma lista de tokens em set\n",
        "s1_set = set(nltk.word_tokenize(s1, language='portuguese'))\n",
        "s2_set = set(nltk.word_tokenize(s2, language='portuguese'))\n",
        "\n",
        "nltk.jaccard_distance(s1_set, s2_set)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5833333333333334"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Za1AcYpb19W"
      },
      "source": [
        "#### **Quiz**\n",
        "\n",
        "1. Qual etapa de pré-processamento poderíamos aplicar para obter uma pontuação ainda maior de Jaccard no exemplo acima? *Dica*: verifique as palavras que não estão fazendo intersecção, porém tem sentido similar.\n",
        "2. No caso das sentenças a seguir, qual o valor de Jaccard? O valor refletiu a similaridade entre as sentenças?\n",
        "\n",
        "**Sentença 1**: Presidente responde a imprensa no Paraná\n",
        "\n",
        "**Sentença 2**: Bolsonaro fala em Curitiba\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import RSLPStemmer\n",
        "nltk.download('rslp')\n",
        "\n",
        "# Sentenças originais\n",
        "s1 = 'Eu gosto de fazer programas usando processamento de linguagem natural'\n",
        "s2 = 'Eu sei programar técnicas de processamento de linguagem natural'\n",
        "\n",
        "# Tokenização\n",
        "s1_tokens = nltk.word_tokenize(s1, language='portuguese')\n",
        "s2_tokens = nltk.word_tokenize(s2, language='portuguese')\n",
        "\n",
        "# Stemming\n",
        "stemmer = RSLPStemmer()\n",
        "s1_stemmed = [stemmer.stem(token) for token in s1_tokens]\n",
        "s2_stemmed = [stemmer.stem(token) for token in s2_tokens]\n",
        "\n",
        "# Convertendo para conjuntos\n",
        "s1_set = set(s1_stemmed)\n",
        "s2_set = set(s2_stemmed)\n",
        "\n",
        "# Calculando a distância Jaccard com stemming\n",
        "distancia_jaccard_stemmed = nltk.jaccard_distance(s1_set, s2_set)\n",
        "\n",
        "print(\"Distância Jaccard original:\", nltk.jaccard_distance(set(s1_tokens), set(s2_tokens)))\n",
        "print(\"Distância Jaccard com stemming:\", distancia_jaccard_stemmed)\n",
        "\n",
        "\n",
        "#A distância Jaccard com stemming deve ser menor do que a distância Jaccard original, indicando que a aplicação do stemming aumentou a similaridade percebida entre as sentenças. Isso ocorre porque palavras como \"programas\" e \"programar\" são reduzidas ao mesmo radical \"program\", aumentando a intersecção entre os conjuntos e, consequentemente, diminuindo a distância Jaccard."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFj1F94L7ftm",
        "outputId": "eccf0ebb-d9f4-4081-d369-3c2c68ac250e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distância Jaccard original: 0.5833333333333334\n",
            "Distância Jaccard com stemming: 0.45454545454545453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]   Unzipping stemmers/rslp.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O gabarito para as atividades práticas propostas estão [aqui](https://colab.research.google.com/drive/1-CtW1Y5GTGc2tm7fxXC5SY8_RB75DviC#scrollTo=SDCy7V1GxQKH)."
      ],
      "metadata": {
        "id": "ZTa0rhMOjVP5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yc0qL2PBGYLn"
      },
      "source": [
        "## Referências e Material complementar\n",
        "\n",
        "*   [Edit Distance & Jaccard](https://python.gotrained.com/nltk-edit-distance-jaccard-distance/)\n",
        "*   [N-Grams Tutorial](https://www.kaggle.com/rtatman/tutorial-getting-n-grams)\n",
        "*   [Introduction to N-Grams: What Are They and Why Do We Need Them?](https://blog.xrds.acm.org/2017/10/introduction-n-grams-need/)\n",
        "*   [Overview of Text Similarity metrics](https://towardsdatascience.com/overview-of-text-similarity-metrics-3397c4601f50)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBsfuc41rkZi"
      },
      "source": [
        "Este notebook foi produzido por Prof. [Lucas Oliveira](http://lattes.cnpq.br/3611246009892500)."
      ]
    }
  ]
}